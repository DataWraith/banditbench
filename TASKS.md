# Tasks

Tasks for use with the [xc](https://xcfile.dev/) Task Runner.

Invoke it with `xc -file TASKS.md update-readme`.

## run-experiments

Runs all currently defined experiments.

Directory: ./experiments

```sh
./run_experiments.rs
```

## result-tables

Converts the `.csv`-files generated by the experiments into a Markdown table.

Directory: ./experiments
Requires: run-experiments

```bash
for RESULT_FILE in *.csv; do
  REPORT_FILE="${RESULT_FILE%.csv}.md"

  sort -n -t ';' -k 3,3 $RESULT_FILE -o $RESULT_FILE

  echo "| Algorithm | %-Optimal | Regret (Mean) | Regret (Median Absolute Deviation) | Time |" > $REPORT_FILE
  echo "|---|---:|---:|---:|:--:|" >> $REPORT_FILE

  cat $RESULT_FILE | sed 's/.*/|&|/' | sed 's/\;/\|/g' >> $REPORT_FILE
done
```

## aggregate-ranks

Computes the aggregate ranking of all algorithms over all experiments.

Directory: ./experiments
Requires: run-experiments
Requires: result-tables

```bash
uv run aggregate_ranks.py

echo "| Algorithm | Average Rank | Average Time (seconds) |" > aggregated_ranks.md
echo "|---|---|---|" >> aggregated_ranks.md
cat aggregated_ranks.csv | sed 's/.*/|&|/' | sed 's/\;/\|/g' >> aggregated_ranks.md
```

## update-readme

Run all experiments and update the README.md file with the results.

Directory: .
Requires: result-tables
Requires: aggregate-ranks

```sh
mdsh
prettier --write README.md
```
